---
title: 大家好，我是唐斩，这是第115天第132篇分享。
date: '2025-12-01'
category: thought
originalPath: /Users/tangchao/Documents/tangzhanx/share/2025/202512/20251201_D115E132.md
---
# 大家好，我是唐斩，这是第115天第132篇分享。


## Ilya 播客对谈和思考

参考《机器之心》的报道
https://mp.weixin.qq.com/s/fGlYeGC79wQI_XVX5qnoRw

- 工业界，大公司，仍然在 transformer 架构的基础上，进行大力出奇迹的行动，堆卡，堆数据，堆参数。这是商业公司的必然选择，在已验证的可规模化的方向上出力。但同时也是有创新的(各种注意力机制，混合专家机制等等)，大力的同时也是巧力。学界，科学家们的终点仍然是 AGI，有观点是 transformer 架构无法达到 AGI ，架构本身的限制发展到最后会触及物理极限(对算力的需求高，神经网络参数的实时调整性差)，甚至神经网络的架构，物理芯片本身的制程已经要到物理极限了。所以科学家们是要去探索新架构的，包括liya、hinton都是这样，这是健康的分工方式。
- RL对模型的影响，塑造了专业性但失去了通用性。人治(指人为设置奖励，设计评测集)的不可避免的结果。
- 人类有漫长时间通过进化埋进身体和大脑的先验知识，体现出来就是学习很快。那模型训练实际是极大压缩了千万甚至亿年时间的自然进化过程。(举例，人类小孩的视觉足够用于驾驶，而自动驾驶模型的视觉训练要花很大代价)。
- 模型的自我对弈，用来获取数据(不同模型的预训练数据已经趋同了，后训练数据能产生个性但依赖人工挑选使得模型会降低泛化能力) 或直接用于模型学习(我听起来就像是对抗网络的模式GAN，并不新颖啊?)，没有实际案例的原因，对弈可适用场景有限(比如谈判、冲突、社交)，真正的对弈不应该是棋盘化的，应该是智能体们在真实环境下类似大自然竞争的方式(从温床里放到实际环境，有点crazy，你的网友们实际是智能体?)。非常有趣的是 DeepSeek新发布的 MathV2 模型，正是应用了对弈机制来解决数学问题的推理解法，而不是暴力解法。

自媒体对这篇访谈报道的标题是 scalling law 已失效，纯粹是标题党，实际是双线并行，大厂继续堆料，SSI走科研路线。看来真正的科学家会很怀念GPT3之前的纯粹的OpenAI的氛围。就像我们也会怀念在小而美时候的公司氛围一样。科学家和企业家，只要有成果，对我们都是好事✌️。


