---
title: 大家好，我是唐斩，这是第110天第127篇分享。
date: '2026-01-10'
category: script
originalPath: >-
  /Users/tangchao/Documents/tangzhanx/video/2025/20251127ccopus45/badcase2
  长段落.md
---
# 大家好，我是唐斩，这是第110天第127篇分享。

## marble 世界模型体验

剑宗or气宗传一张图加一段文字描述就能生成一个3D世界也许是通往AGI的另外一条路NanoBanana 团队曾经分享过他们的洞察文字是生图质量的核心，文字本身就是一种高要求的图，不出所料的 NanoBanana Pro 里，模型完美克服了图片中生成文字的问题。延展思考，那图片是不是生成视频质量的核心？ 视频是不是世界在特定时间和特定镜头下的输出？ 那进一步推断视频是生成世界的核心？ 所以最终得出，文字就是世界的核心，从文字出发去训练模型最终能得到世界模型。我称这个逻辑是剑宗路线，以文字为剑。自底向上，从微观开始搭建，逐步完成整体。marble世界模型则是反过来的，从宏观开始，逐步精细化微观，我称之为气宗路线，原生得从空间角度思考和训练模型，也就是“空间智能”，天生有比纯文字更丰富的信息。

虽然现在生成的世界规模还不大(一个房间)，还不能实时生成(无边界加载)，生成精度还不够(达不到真实世界的程度，以动画世界为主)。但可以在世界中开上帝视角遨游，可以部分编辑世界，还是很惊艳的。

从24年初成立，到现在2年时间，可以完成到这个程度，很厉害了。并且从李飞飞的官方文章内容看，空间智能的未来想象空间还非常大。
现在短期的影响主要在3D艺术创作和游戏视觉设计两个领域，相当于给他们提供了一种 Vibe Create 的方式。类似Code Agent给程序员带来的 VibeCoding。

worldlabs李飞飞说明的未来的发展方向
1、现实模拟
现在生成出来的世界还只能“看”，不能“摸”。一旦加入可交互，将会是超级大的里程碑。
那时候就可以 vibe 生成3d虚拟游戏了。
最终将可以模拟物理世界。缸中宇宙，matrix 世界的开端！

2、具身智能
把空间智能装入到具身智能上，可能是直打L4的途径。
智能驾驶领域现在有共识L2做的越好的，离L4就越远。在具身智能上应该也是同理。

3、教育，VR/AR
我觉得和前面相比，教育只是小场景了。在视频之上，可以和世界交互去直观学习。
会有一个核心问题，就是交互形式。
很容易想到 VR 化，才是终极交互，就回到 matrix 的路径了。
我倒是觉得 AR/MR 会更惊叹。想象左眼真实世界，实时输入实时生成虚拟空间，右眼在虚拟世界中可以做什么？
预测世界发展来优化现实世界的选择，和好友实时共享世界，实时二创(我即上帝)很有想象力。

要解决的问题
-版权问题
但还没看到空间智能的底层技术资料，期待后续 worldlabs 和 google 的发挥了！
值得长期关注。
