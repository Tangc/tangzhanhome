# 大家好，我是唐斩，这是第110天第127篇分享。

## marble 世界模型体验，剑宗or气宗
- 传一张
- 图加一
- 段文字
- 描述就
- 能生成一个
- 3D世界
- 也许是通
- 往AGI的
- 另外一条路
- NanoBanana 
- 团队曾
- 经分享过
- 他们的洞察
- 文字是生图质
- 量的核心，文字本身
- 就是一种高要求的图，不出所料的 
- NanoBanana Pro 里，模型完美克
- 服了图片中生成文字
- 的问题。延展思考，那图片是不是生成视频质
- 量的核心？ 视频是不
- 是世界在特定时间和特定
- 镜头下的输出？ 那进一步推断
- 视频是生成世界的核心？ 
- 所以最终得出，文字就是
- 世界的核心，从文字出发
- 去训练模型最终能得到世界模型。

我称这个逻辑是剑宗路线，以文字为剑。自底向上，从微观开始搭建，逐步完成整体。

marble世界模型则是反过来的，从宏观开始，逐步精细化微观，我称之为气宗路线，原生得从空间角度思考和训练模型，也就是“空间智能”，天生有比纯文字更丰富的信息。
虽然现在生成的世界规模还不大(一个房间)，还不能实时生成(无边界加载)，生成精度还不够(达不到真实世界的程度，以动画世界为主)。
但可以在世界中开上帝视角遨游，可以部分编辑世界，还是很惊艳的。

从24年初成立，到现在2年时间，可以完成到这个程度，很厉害了。并且从李飞飞的官方文章内容看，空间智能的未来想象空间还非常大。
现在短期的影响主要在3D艺术创作和游戏视觉设计两个领域，相当于给他们提供了一种 Vibe Create 的方式。类似Code Agent给程序员带来的 VibeCoding。

worldlabs李飞飞说明的未来的发展方向
1、现实模拟
现在生成出来的世界还只能“看”，不能“摸”。一旦加入可交互，将会是超级大的里程碑。
那时候就可以 vibe 生成3d虚拟游戏了。
最终将可以模拟物理世界。缸中宇宙，matrix 世界的开端！

2、具身智能
把空间智能装入到具身智能上，可能是直打L4的途径。
智能驾驶领域现在有共识L2做的越好的，离L4就越远。在具身智能上应该也是同理。

3、教育，VR/AR
我觉得和前面相比，教育只是小场景了。在视频之上，可以和世界交互去直观学习。
会有一个核心问题，就是交互形式。
很容易想到 VR 化，才是终极交互，就回到 matrix 的路径了。
我倒是觉得 AR/MR 会更惊叹。想象左眼真实世界，实时输入实时生成虚拟空间，右眼在虚拟世界中可以做什么？
预测世界发展来优化现实世界的选择，和好友实时共享世界，实时二创(我即上帝)很有想象力。

要解决的问题
-版权问题
但还没看到空间智能的底层技术资料，期待后续 worldlabs 和 google 的发挥了！
值得长期关注。

