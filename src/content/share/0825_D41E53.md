分享 D41E53
1、评估 AI Agent 的效果
评估是做AI Agent产品的一个难点，不像传统软件功能一般是操作交互可数的硬性的，通过功能测试可以覆盖绝大多数场景。
而现在的AI Agent通过自然语言交互，是软性的，评估AI Agent的效果是很困难的。

听到过一个播客节目，讲大模型产品的产品经理，要自己藏着一套不给研发看的测试题，用来评估训练出来的模型效果。

我认为对Agent的测试会比较像搜索引擎或者推荐系统的测试，随着面向数据集的增加，要有从硬性全覆盖测试到软性渐进测试的思维转变。

2、怎么评估
具体可行的做法：
- 基准。使用公共测试集，像模型冲榜的那些能力判定，也是一种评估。
- 核心。维护自己的测试集，尽量覆盖核心场景和致命场景。致命如涉政黄赌毒等话题。
- 边界。建立用户反馈机制，从业务数据来监控产品体验，利用用户反馈来补充边界场景。


合理的评估体系是AI Agent产品的必要组成部分，也应该是AI Agent产品研发的一项差异化核心能力。