# 《AI原生应用架构白皮书》全章节要点整理

大家好，我是唐斩，这是第70天第85篇分享。
## 阿里云《AI原生应用白皮书》框架部分的内容记录
- 早期python为主，langchain为代表，国内企业级市场Java有广泛使用，所以推荐使用 Spring Alibaba AI 框架。
 - 基于 Spring AI(对标 langchain)，对标 langchain graph。开箱即用。
 - 现在逐步在往里面加 alibaba 的全家桶，比如 nacos register 等。(用的时候要自己理一下依赖)
- Agent 从简单到复杂，有 单Agent、多Agent、分布式Agent
 - 从单Agent开始开发总是没错的，可以理解Agent的开发模式。
 - 多 Agent 有多种构建模式，以拓扑结构来看，有线形、并行、主从等等，框架都支持。
 - Agent 内部推荐用 ReAct 模式(经典模式，听过论文作者的播客，openai研究员)
- 企业级分布式部署阶段，可借助框架的成熟方案
 - A2A，google推出的Agent通讯协议
 - nacos 负责做 Agent 的注册中心，并且支持自动注册和发现
如果准备用。Spring Alibaba AI 框架来开发Agent的话，内容还是不错的，方便上手。

## 阿里云《AI原生应用白皮书》上下文工程部分的内容记录，
借用经典论文All you need is attention 的格式，我理解上下文工程的内核就是 "All LLM need is Infomation"，给LLM提供正确的适当的充足的信息，就是上下文工程的目标。
具体的内容有
- 提示词工程，优秀提示词的最佳实践，包括
 - 设定专家角色(你是XXX)
 - 明确AI需要知道的信息(做什么事情，有什么前提条件，有什么要求限制等，尽量列清楚)
 - 给出示例(few-shot，效果会很好，特别是用来避免badcase、边界case等)
 - 定义结构化输出(特别是json格式，API调用时几乎必需)
- 上下文工程，对提示词工程范围的扩展 (提示词工程仅关心单次交互 vs 上下文工程关心全生命周期)，关键技术
 - RAG，增强检索。 (比微调更灵活，更实时织入专有信息的手段，通过向量化突破了传统检索的信息量上限，损失精度但能支持更大量的数据) RAG值得单独开一篇细讲，后续分享
 - 记忆，既补充历史信息，又避免上下文爆炸的关键点。细节也可展开，后续分享
上下文工程前两个月特别火，值得一看的有manus的官方经验、定义概念的kapathy大神的原文等。

## 阿里云《AI原生应用白皮书》工具部分的内容记录
工具之于大模型，可以比喻为手之于大脑，让大模型可以和已有的互联网世界，甚至是物理世界打通。
两种工具：
- Function Calling，最早出现的方案，和模型绑定，不能跨模型复用(甚至要猜测模型有什么tools，引导模型去使用)
- MCP，Anthropic推出的标准化协议，一般被比做USB口，突出一个通用，有万物MCP的趋势，只要你有一个MCP的口子，就可以接入到大模型里面去。
MCP详细介绍，客户端服务端模式，采用 JSON-RPC 2.0 通信规范(处处透露了通用性，JSON意味着可跨语言跨平台)。
企业级应用的痛点：
- 安全问题，自身不带认证体系，需自己实现。
- 数量问题，太多MCP会让模型选择困难，也浪费token
- 管理问题，不同的MCP服务平台有不同的配套设施，难以统一管理(如观测，计量等等)
解决方案：（这两段其实就是阿里在兜售自己的方案了，独立开发的话不用管)
- 安全问题，通过阿里云API网关解决
- 数量问题，通过阿里Qwen3的 Embedding 和 Reranker 模型压缩 tools 数量。(一次mini的rag过程，实现精排)
- 管理问题，通过阿里的 Nanos 注册 MCP，通过阿里的 HiMarket 管理 MCP 服务。
国外已经有广泛集成 MCP 的服务平台了，例如 Composier、Rube 等，独立开发的话可以体验使用，也能解决上述问题。

## 阿里云《AI原生应用白皮书》网关部分的内容记录
- 网关的演进，是随着服务架构一起演进的。流量网关for单体架构，ESB网关forSOA架构，微服务网关for云原生架构，AI网关forAI原生架构
- AI流量的特征，高延时(LLM思考然后回复)、大带宽(文本量大)、流式传输(一点一点返回)、长链接(粘连性，有状态)
- AI网关的场景，模型服务商入口(比如硅基流动)、AI应用的网关(比如对接多模型fallback切换)、企业内部的统一AI网关(比如公司统一提供AI能力的入口)、MCP 集市入口(我觉得有点牵强，纯为了引出 higress 的 MCP 市场)
- AI网关的核心能力(这条开始就完全是对着 higress 在讲了，对于本书标题没有写明只介绍阿里的AI原生架构来说，显得很不公正，屁股歪歪)，多模型代理、多模型容灾、用户认证、安全审计、限流、缓存、可观测、MCP代理(http无感转mcp)、工具组装和路由(缩减工具量和选择正确的工具)。

## 阿里云《AI原生应用白皮书》运行时部分的内容记录
- 传统 serverless 架构面向确定性、无状态、短周期HTTP请求，不符合动态性、有状态、长周期复杂交互的 Agent 场景
- AI原生应用运行时需要的核心能力是
  - 会话级状态管理和安全隔离(有虚拟运行代码能力时需要硬隔离)
  - 实时弹性和成本核算(毫秒伸缩、实际用量计费)
  - 异构算力和工具连接(cpu、gpu资源分别核算，mcp、a2a连接)
- Agent 运行时的核心架构目标
  - 围绕会话(session)，支持状态持久化的可弹性系统(区别于基于请求-响应的互联网HTTP场景)
  - 灵活资源管理，文件、内容、cpu、gpu丰富资源的灵活和准确的计时机费


## 阿里云《AI原生应用白皮书》可观测部分的内容记录
- 可观测相比监控，跟强调能解释为什么，而不只是呈现一堆的数据
- AI可观测的关键能力项
  - 端到端全链路追踪(AI应用的端是从用户输入到最底层的大模型内部，而不同于传统应用底层是数据)
  - 全栈可观测(终端层、网关层、应用层、模型层多个维度)
  - 自动化评估，因为AI应用的不确定性，引入评估Agent来实现自动化评估(类似对抗的思路，但不会更加复杂了吗。绕一下，评估Agent能评估评估Agent吗？)
- 端到端全链路追踪的实现要点，面向AI应用的Trace语义(拆解AI应用的流程节点，比如 LLM、TOOL等节点)、支持多语言客户端的接入(python、java、go等)、标准化协议，兼容 OpenTelemetry W3C 协议，以实现跨语言组件的透传
- 推理引擎的可观测，推理引擎是运行LLM的软件，以开源的vLLM最常见。核心职责是 KVCache、GPU调度、分词调用LLM。根据其内部架构需要可以观测到如温度、topk、推理首token时间等细节内容。

## 阿里云《AI原生应用白皮书》评估部分的内容记录
- AI应用 VS 传统应用。 非确定性和概率性的 VS 确定性和规则性的。 相同输入不同输出 VS 相同输入相同输出。
- 幻觉，AI应用的阿克琉斯之踵，既是不可靠的根源，也是其创造力的源泉。
- 评估是AI治理的基石，评估体系应包含8个核心组件，性能、鲁棒与泛化、偏见与公平性、可解释性、合规性与伦理、持续监控、决策框架、自动化。(有点理论)
- LLM-as-a-Judge，基于 Agent 评估，解决人工评估的局限性。评估这个事情本身也可视为LLM的舒适区(海量、评判、可柔性)，因此有合理性。也要认识到Agent评估的局限性，Agent本身的偏见 和 LLM本身的能力上限。最好的方式还是人工和Agent评估同时使用，持续观察迭代。Agent评估亦有不同程度，可定义L0到L5。
- 阿里云提供的云原生评估方案，包括能力有 数据采集、预处理、实时评估、模板化。


## 阿里云《AI原生应用白皮书》AI安全部分的内容记录
- AI安全风险的来源，系统(AI底层软件带来的系统漏洞等)、网络(入侵、攻击等)、身份(Agent本身行为的管控)、数据(数据投毒，敏感信息)、模型(提示词攻击)、应用(入侵攻击等)
- 应用安全，新场景有 DoW (诱导AI持续消耗Token)。模型安全，新场景有 提示词注入(触发底层系统漏洞), 推理层攻击(模型伦理失控，比如google的go die事件，RAG知识库爬取)， 输出内容攻击(比如生成政府银行等政治、资产、权威性的内容)。身份安全，保护各种key、密钥的安全。其余的数据、网络安全等主要体现在云厂商内部，不做详述。


## 《AI原生应用架构白皮书》总结
有助于俯瞰AI应用的全景，理解如果要在阿里云部署AI应用，可以用到哪些组件，从云原生的角度，阿里云平台为AI应用提供了哪些能力。
浅层内容，快速扫一遍即可。

后续会继续分享用 Spring Alibaba AI 框架开发 Agent 的经验实践。